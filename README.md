### Biography

I am a 6th year Ph.D. student in the Department of Electrical and Computer Engineering at Johns Hopkins University, Baltimore, MD. I work with Najim Dehak and Jes√∫s Villalba at the [Center for Language and Speech Processing](https://www.clsp.jhu.edu "CLSP"). I am currently focussed on  adapting speaker recognition systems to far-field and noisy data using unsupervised techniques. I am also working on dealing with channel mismatch. 

Previously, I had worked with Prof. Hynek Hermansky with research focussed on noise robust Automatic Speech Recognition (ASR). I also collaborate with Dan Povey on developing an augmentation recipe for ASR. My contributions to Kaldi can be found on [my github](https://github.com/phanisankar-nidadavolu/kaldi/commits/augmentation-script-asr-spkrid "Augmentation Recipe"). 

### Research Interests

Speaker Recognition and Diarization, Automatic Speech Recognition, Machine Learning, Speech Signal Processing

### Other Information
 
  [Google Scholar](https://scholar.google.com/citations?user=v5-ThlEAAAAJ&hl=en&oi=ao)

  [Linkedin](https://www.linkedin.com/in/phanisankar-nidadavolu/)
  
  [Github](https://github.com/phanisankar-nidadavolu)
  
  
### News

Actively looking for a Research Scientist role in industry. 


### Education

* [Johns Hopkins University](https://www.jhu.edu), Baltimore, MD, USA

      Ph.D. Candidate in Electrical Engineering (2013 - present)
      Master of Science in Engineering (MSE) (2013-2019) with specialization in Electrical Engineering


* [Indian Institute of Technology (IIT) Kanpur](https://www.iitk.ac.in/ee/)

      Master of Technology (MTech) (2007-2009) in Electrical Engineering

      Thesis Topic: Fault Diagnosis of Internal Combustion Engines Using Neural Networks

      Thesis Advisor: Prof. Prem Kumar Kalra


### Research Workshops

2019 Sixth Frederick Jelinek Memorial Summer Workshop [JSALT 2019]()


### Other Research Projects

*Robust Automatic Transcription of Speech (RATS)*: Funded by DARPA (2013-2014)

Worked on developing a Long, Deep and Wide Neural Network (LDWNN) for improving the robustness of ASR acoustic models to noisy and degraded speech. Work submitted to [INTERSPEECH 2014](https://www.isca-speech.org/archive/archive_papers/interspeech_2014/i14_0358.pdf "LDWNN")

*NIST 2016 Speaker Recognition Evaluation*

Worked on developing a state-of-the-art speaker recognition system in collaboration with MIT Lincoln Laboratory. Work submitted to [INTERSPEECH 2017](http://mallidi.github.io/pdfs/Pedro_NIST-SRE2016_sys_paper_Interspeech2017.pdf)


*NIST 2012 Speaker Recognition Evaluation*

Worked on developing a speaker recognition system with i-vectors trained on cepstral coefficients extracted from smoothed sub- band instantaneous frequencies (IFCC) features. Work was done in Speech and Image Processing (SIP) Lab, IIT Hyderabad. 


### Publications


List of my publications can be found in my [Google Scholar](https://scholar.google.com/citations?user=v5-ThlEAAAAJ&hl=en&oi=ao)

Arxiv links for my publications which are in preprint or under review


### Work Experience


### Teaching


### Contact Information
   Can be found on my [Linkedin](https://www.linkedin.com/in/phanisankar-nidadavolu/)
