### Biography

I am a 6th year Ph.D. student in the Department of Electrical and Computer Engineering at Johns Hopkins University, Baltimore, MD. I work with Najim Dehak and Jesús Villalba at the [Center for Language and Speech Processing](https://www.clsp.jhu.edu "CLSP"). I am currently focussed on  adapting speaker recognition systems to far-field and noisy data using unsupervised techniques. I am also working on dealing with channel mismatch. 

Previously, I had worked with Prof. Hynek Hermansky with research focussed on noise robust Automatic Speech Recognition (ASR). I also collaborate with Dan Povey on developing an augmentation recipe for ASR. My contributions to Kaldi can be found on [my github](https://github.com/phanisankar-nidadavolu/kaldi/commits/augmentation-script-asr-spkrid "Augmentation Recipe"). 

### Research Interests

Speaker Recognition and Diarization, Automatic Speech Recognition, Machine Learning, Speech Signal Processing

### Other Information
 
  [Google Scholar](https://scholar.google.com/citations?user=v5-ThlEAAAAJ&hl=en&oi=ao)

  [Linkedin](https://www.linkedin.com/in/phanisankar-nidadavolu/)
  
  [Github](https://github.com/phanisankar-nidadavolu)
  
  
### News

Actively looking for a Research Scientist role in industry. 


### Education

* [Johns Hopkins University](https://www.jhu.edu), Baltimore, MD, USA

     Ph.D. Candidate in Electrical Engineering (2013 - present)
     
     Master of Science in Engineering (MSE) (2013-2019) with specialization in Electrical Engineering


* [Indian Institute of Technology (IIT) Kanpur](https://www.iitk.ac.in/ee/), India

     Master of Technology (MTech) (2007-2009) in Electrical Engineering
     
     Thesis Topic: Fault Diagnosis of Internal Combustion Engines Using Neural Networks
     
     Advisor: Prof. Prem Kumar Kalra

### Internships
1. **Research Intern, Spoken Communications** 

      Reporting Manager: [Yishay Carmiel](https://www.linkedin.com/in/yishay-carmiel-6469482/), Oct-Dec 2017
2. **Research Intern at Apple Inc**
   
      IMG Audio group, June-Aug 2015
    
### Research Workshops

* **JSALT 2019** - Speaker Detection in Adverse Scenarios with a Single Microphone [[homepage]](https://www.clsp.jhu.edu/workshops/19-workshop/speaker-detection-in-adverse-scenarios-with-a-single-microphone/)

     Worked on unsupervised feature enhancement of reverberant/noisy speech using real data from target domain to improve the robustness of speaker recognition systems. Work submitted to ICASSP 2020. 
     
* **HLTCOE-SCALE 2017** - Speaker Recognition in Multimedia Data [[homepage]](https://hltcoe.jhu.edu/research/scale/scale-2017/)

     Worked on unsupervised channel adaptation (multi-media to telephone domain) using adversarial learning. Work submitted to ICASSP 2019. 
     
* **JSALT 2016** - Remote Monitoring of Neurodegeneration through Speech [[homepage]](https://www.clsp.jhu.edu/workshops/16-workshop/remote-monitoring-of-neurodegeneration-through-speech/)

     Worked on detecting presence of Alzheimer’s disease (AD) and Parkinson’s disease (PD) from i-vectors. Worked on building and adapting Automatic Speech Recognition (ASR) systems for the tasks. 



### Other Research Projects

* **Robust Automatic Transcription of Speech (RATS)**: Funded by DARPA (2013-2014)

     Worked on developing a Long, Deep and Wide Neural Network (LDWNN) for improving the robustness of ASR acoustic models to noisy and degraded speech. Work submitted to Interspeech 2014.

* **NIST 2016 Speaker Recognition Evaluation**

     Worked on developing a state-of-the-art speaker recognition system in collaboration with MIT Lincoln Laboratory. Work submitted to Interspeech 2017.


* **NIST 2012 Speaker Recognition Evaluation**

     Worked on developing a speaker recognition system with i-vectors trained on cepstral coefficients extracted from smoothed sub- band instantaneous frequencies (IFCC) features. Work was done in Speech and Image Processing (SIP) Lab, IIT Hyderabad. 


### Selected Publications

Complete list of my publications can be found in my [Google Scholar Profile](https://scholar.google.com/citations?user=v5-ThlEAAAAJ&hl=en&oi=ao)

   1. Phani Sankar Nidadavolu, Jesús Villalba, Najim Dehak. "Cycle-GANs for Domain Adaptation of Acoustic Features for Speaker Recognition." ICASSP 2019.  
   2. Phani Sankar Nidadavolu, Vicente Iglesias, Jesús Villalba, Najim Dehak. "Investigation on Neural Bandwidth Extension of Telephone Speech for Improved Speaker Recognition." ICASSP 2019. 
   3. Phani Sankar Nidadavolu, Cheng-I Lai, Jesús Villalba, Najim Dehak. "Investigation on Bandwidth Extension for Speaker Recognition." Interspeech 2018. 
   4. Feipeng Li, Phani Sankar Nidadavolu, and Hynek Hermansky. "A Long, Deep and Wide Artificial Neural Net for Robust Speech Recognition In Unknown Noise." In Interspeech 2015.



* **Preprint**

     1. Phani Sankar Nidadavolu et.al. "Low-Resource Domain Adaptation for Speaker Recognition Using Cycle-GANs". Accepted at ASRU 2019 [[arxiv]](https://arxiv.org/abs/1910.11909)
     2. Phani Sankar Nidadavolu et.al. "Unsupervised Feature Enhancement for speaker verification". Submitted to ICASSP 2020 [[arxiv]](https://arxiv.org/abs/1910.11915)
     3. Saurabh Kataria, Phani Sankar Nidadavolu et. al. "Feature Enhancement with Deep Feature Losses for Speaker Verification". Submitted to ICASSP 2020 [[arxiv]](https://arxiv.org/abs/1910.11905)


### Work Experience

1. 	**Project Associate, June 2012-May 2013**

       Speech and Image Processing (SIP) Lab, IIT Hyderabad, India 
2. **Design Engineer, Aug 2009-June 2012**

      Dar Al-Handasah Consultants, Pune, India

### Teaching Assistant

1. EN.520.612 Machine Learning for Signal Processing  - Ongoing

2. EN.520.123 Computational Modeling for Electrical and Computer Engineering - Spring 2017 & Spring 2019

3. EN.525.627 Digital Signal Processing - Fall 2016 

4. EN.520.515 Processing of Audio and Visual Signals - Fall 2014


### Contact Information
   snidada1 at jhu dot edu
