### Biography

I am a 6th year Ph.D. student in the Department of Electrical and Computer Engineering at Johns Hopkins University, Baltimore, MD. I work with Najim Dehak and Jesús Villalba at the [Center for Language and Speech Processing](https://www.clsp.jhu.edu "CLSP"). I am currently focussed on  adapting speaker recognition systems to far-field and noisy data using unsupervised techniques. I am also working on dealing with channel mismatch. 

Previously, I had worked with Prof. Hynek Hermansky with research focussed on noise robust Automatic Speech Recognition (ASR). I also collaborate with Dan Povey on developing an augmentation recipe for ASR. My contributions to Kaldi can be found on [my github](https://github.com/phanisankar-nidadavolu/kaldi/commits/augmentation-script-asr-spkrid "Augmentation Recipe"). 

### Research Interests

Speaker Recognition and Diarization, Automatic Speech Recognition, Machine Learning, Speech Signal Processing

### Other Information
 
  [Google Scholar](https://scholar.google.com/citations?user=v5-ThlEAAAAJ&hl=en&oi=ao)

  [Linkedin](https://www.linkedin.com/in/phanisankar-nidadavolu/)
  
  [Github](https://github.com/phanisankar-nidadavolu)
  
  
### News

Actively looking for a Research Scientist role in industry. 


### Education

* [Johns Hopkins University](https://www.jhu.edu), Baltimore, MD, USA

     Ph.D. Candidate in Electrical Engineering (2013 - present)
     
     Master of Science in Engineering (MSE) (2013-2019) with specialization in Electrical Engineering


* [Indian Institute of Technology (IIT) Kanpur](https://www.iitk.ac.in/ee/), India

     Master of Technology (MTech) (2007-2009) in Electrical Engineering
     
     Thesis Topic: Fault Diagnosis of Internal Combustion Engines Using Neural Networks
     
     Thesis Advisor: Prof. Prem Kumar Kalra

### Internships
1. **Research Intern, Spoken Communications** 

      Reporting Manager: [Yishay Carmiel](https://www.linkedin.com/in/yishay-carmiel-6469482/), Oct-Dec 2017
2. **Research Intern at Apple Inc**
   
      IMG Audio group, June-Aug 2015
    
### Research Workshops

* **JSALT 2019** - Speaker Detection in Adverse Scenarios with a Single Microphone [homepage](https://www.clsp.jhu.edu/workshops/19-workshop/speaker-detection-in-adverse-scenarios-with-a-single-microphone/)

     Worked on unsupervised feature enhancement of reverberant/noisy speech using real data from target domain to improve the robustness of speaker recognition systems. Work submitted to [ICASSP 2020](https://arxiv.org/abs/1910.11915). 
     
* **HLTCOE-SCALE 2017** - Speaker Recognition in Multimedia Data [homepage](https://hltcoe.jhu.edu/research/scale/scale-2017/)

     Worked on unsupervised channel adaptation (multi-media to telephone domain) using adversarial learning. Work submitted to [ICASSP 2019](https://ieeexplore.ieee.org/abstract/document/8683055). 
     
* **JSALT 2016** - Remote Monitoring of Neurodegeneration through Speech [homepage](https://www.clsp.jhu.edu/workshops/16-workshop/remote-monitoring-of-neurodegeneration-through-speech/)

     Worked on detecting presence of Alzheimer’s disease (AD) and Parkinson’s disease (PD) from i-vectors. Worked on building and adapting Automatic Speech Recognition (ASR) systems for the tasks. 



### Other Research Projects

* **Robust Automatic Transcription of Speech (RATS)**: Funded by DARPA (2013-2014)

     Worked on developing a Long, Deep and Wide Neural Network (LDWNN) for improving the robustness of ASR acoustic models to noisy and degraded speech. Work submitted to [INTERSPEECH 2014](https://www.isca-speech.org/archive/archive_papers/interspeech_2014/i14_0358.pdf "LDWNN")

* **NIST 2016 Speaker Recognition Evaluation**

     Worked on developing a state-of-the-art speaker recognition system in collaboration with MIT Lincoln Laboratory. Work submitted to [INTERSPEECH 2017](http://mallidi.github.io/pdfs/Pedro_NIST-SRE2016_sys_paper_Interspeech2017.pdf)


* **NIST 2012 Speaker Recognition Evaluation**

     Worked on developing a speaker recognition system with i-vectors trained on cepstral coefficients extracted from smoothed sub- band instantaneous frequencies (IFCC) features. Work was done in Speech and Image Processing (SIP) Lab, IIT Hyderabad. 


### Selected Publications

Complete list of my publications can be found in my [Google Scholar Profile](https://scholar.google.com/citations?user=v5-ThlEAAAAJ&hl=en&oi=ao)

   1. Phani Sankar Nidadavolu, Jesús Villalba, Najim Dehak. "Cycle-GANs for Domain Adaptation of Acoustic Features for Speaker Recognition." ICASSP 2019.  [[pdf]](https://ieeexplore.ieee.org/document/8683055)
   2. Phani Sankar Nidadavolu, Vicente Iglesias, Jesús Villalba, Najim Dehak. "Investigation on Neural Bandwidth Extension of Telephone Speech for Improved Speaker Recognition." ICASSP 2019. [[pdf]](https://ieeexplore.ieee.org/document/8682992)
   3. Phani Sankar Nidadavolu, Cheng-I Lai, Jesús Villalba, Najim Dehak. "Investigation on Bandwidth Extension for Speaker Recognition." Interspeech 2018. [[pdf]](https://www.isca-speech.org/archive/Interspeech_2018/pdfs/2394.pdf)
   4. Feipeng Li, Phani Sankar Nidadavolu, and Hynek Hermansky. "A Long, Deep and Wide Artificial Neural Net for Robust Speech Recognition In Unknown Noise." In Interspeech 2015. [[pdf]](https://www.isca-speech.org/archive/archive_papers/interspeech_2014/i14_0358.pdf)



* **Preprint**

     1. Phani Sankar Nidadavolu et.al. "Low-Resource Domain Adaptation for Speaker Recognition Using Cycle-GANs". Accepted at ASRU 2019 [arxiv](https://arxiv.org/abs/1910.11909)
     2. Phani Sankar Nidadavolu et.al. "Unsupervised Feature Enhancement for speaker verification". Submitted to ICASSP 2020 [arxiv](https://arxiv.org/abs/1910.11915)
     3. Saurabh Kataria, Phani Sankar Nidadavolu et. al. "Feature Enhancement with Deep Feature Losses for Speaker Verification". Submitted to ICASSP 2020 [arxiv](https://arxiv.org/abs/1910.11905)


### Work Experience


### Teaching


### Contact Information
   snidada1 at jhu dot edu
